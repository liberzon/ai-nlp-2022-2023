{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Tal Birs 208574905\n",
    "#Maya David 209282532"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       5171 non-null   object\n",
      " 1   label_num  5171 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 80.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "df = df[['text', 'label_num']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply token in the df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False,\n",
    "                             preprocessor=lambda x: x,\n",
    "                             tokenizer=lambda x: x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "docs = df['tokens'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer.fit(docs)\n",
    "vectorizer.get_feature_names()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer.transform(docs)\n",
    "vectorizer.fit_transform(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ham = df[df['label_num'] == 0]\n",
    "df_spam = df[df['label_num'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "build the matrix of the text and counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_matrix(text_df_input, model_input):\n",
    "    matrix = model.fit_transform(text_df_input).toarray()\n",
    "    return pd.DataFrame(data=matrix, columns=model_input.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "split the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('label_num', axis=1)\n",
    "y = df['label_num']\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "show the features of the text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for list in df['tokens']:\n",
    "    vocabulary += list\n",
    "wordset = set(vocabulary)\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=wordset, lowercase=False)\n",
    "print(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(train['text'])\n",
    "df_bow_train = pd.DataFrame(X_train.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "print(df_bow_train.head())\n",
    "print(f'train with {X_train.shape[0]} records with {X_train.shape[1]} features')\n",
    "\n",
    "X_test = count_vectorizer.fit_transform(test['text'])\n",
    "df_bow_test = pd.DataFrame(X_test.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "print(df_bow_test.head())\n",
    "print(f'test with {X_test.shape[0]} records with {X_test.shape[1]} features')\n",
    "\n",
    "y_train = train['label_num']\n",
    "y_test = test['label_num']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "build KNN classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "\n",
    "k= int(math.sqrt(X_train.shape[0])/2)\n",
    "if k%2 ==0:\n",
    "    k+=1\n",
    "\n",
    "clf= KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_test =clf.predict(X_test)\n",
    "\n",
    "knn_acc_score= accuracy_score(y_test, y_pred_test)\n",
    "knn_pre_score=precision_score(y_test, y_pred_test,average='weighted')\n",
    "knn_recall_score=recall_score(y_test, y_pred_test,average='macro')\n",
    "print(\"test scores:\")\n",
    "print(\"Accuracy:\",knn_acc_score)\n",
    "print(\"Precision:\",knn_pre_score )\n",
    "print(\"recall:\",knn_recall_score )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "build SVM model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create svm model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test=model.predict(X_test)\n",
    "svm_acc_score= metrics.accuracy_score(y_test,y_pred_test)\n",
    "svm_pre_score=metrics.recall_score(y_test, y_pred_test)\n",
    "svm_recall_score=metrics.precision_score(y_test, y_pred_test)\n",
    "svm_f_score=metrics.f1_score(y_test,y_pred_test)\n",
    "\n",
    "print(\"accuracy\",svm_acc_score)\n",
    "print(\"recall:\",svm_recall_score)\n",
    "print(\"precision\",svm_pre_score)\n",
    "print(\"f1:\",svm_f_score)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "build Logistic Regression model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf= LogisticRegression(random_state=1234)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test =clf.predict(X_test)\n",
    "logistic_acc_score=metrics.accuracy_score(y_test, y_pred_test)\n",
    "logistic_pre_score=metrics.precision_score(y_test, y_pred_test)\n",
    "logistic_recall_score=metrics.recall_score(y_test, y_pred_test)\n",
    "logistic_f_score= metrics.f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"for test prediction: \")\n",
    "print(\"Accuracy:\",logistic_acc_score)\n",
    "print(\"Precision:\", logistic_pre_score)\n",
    "print(\"recall:\", logistic_recall_score)\n",
    "print(\"F1:\",logistic_f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "build Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1234)\n",
    "model.fit(X_train, y_train)\n",
    "plt.figure(figsize=(15, 20), dpi=100)\n",
    "\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "cm_test = pd.crosstab(y_test, y_pred_test, colnames=['pred'], margins=True)\n",
    "plot_confusion_matrix(model, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "tree_acc_score= metrics.accuracy_score(y_test, y_pred_test)\n",
    "tree_pre_score=metrics.precision_score(y_test, y_pred_test)\n",
    "tree_recall_score= metrics.recall_score(y_test, y_pred_test)\n",
    "tree_f_score=metrics.f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Accuracy:\", tree_acc_score)\n",
    "print(\"Precision:\", tree_pre_score)\n",
    "print(\"recall:\",tree_recall_score)\n",
    "print(\"F1:\", tree_f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "show all the scores in one table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------  ---------  --------  ----------  --------  -------  --------  ---  --------\n",
      "Logistic Regression  Accuracy:  0.978744  Precision:  0.955128  recall:  0.973856  F1:  0.964401\n",
      "SVM                  Accuracy:  0.960386  precision:  0.964052  recall:  0.907692  f1   0.935024\n",
      "Decision Tree        Accuracy:  0.943961  Precision:  0.907895  recall:  0.901961  F1:  0.904918\n",
      "KNN                  Accuracy:  0.822222  Precision:  0.85834   recall:  0.844408\n",
      "-------------------  ---------  --------  ----------  --------  -------  --------  ---  --------\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#create data\n",
    "data = [[\"Logistic Regression\", \"Accuracy:\",logistic_acc_score, \"Precision:\",logistic_pre_score, \"recall:\",                 logistic_recall_score, \"F1:\", logistic_f_score],\n",
    "        [\"SVM\", \"Accuracy:\",svm_acc_score,\"precision:\",svm_pre_score,\"recall:\",svm_recall_score,\"f1\",svm_f_score,],\n",
    "        [\"Decision Tree\", \"Accuracy:\",tree_acc_score, \"Precision:\",tree_pre_score,\"recall:\",tree_recall_score, \"F1:\",tree_f_score],\n",
    "        [\"KNN\", \"Accuracy:\",knn_acc_score,\"Precision:\",knn_pre_score,\"recall:\",knn_recall_score]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"model_name\", \"scores\"]\n",
    "\n",
    "\n",
    "print(tabulate(data, tablefmt=\"simple\" ))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "explain about the scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#the best scores are in logistic regression model and in SVM model\n",
    "# Both models is used to solve binary problems and is therefore suitable for the problem presented #in this data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#SVMs are used for classification and regression problems, but mostly classification. The algorithm creates a hyperplane or line to classify data. It finds the best line separator using the kernel trick (decision boundary that has same distance from the boundary point of both classes). It's a powerful way to learn complex nonlinear functions.\n",
    "#Logistic regression helps classify data. It describes data and explains variable relationships. Logistic regression is used when the output variable (y) ranges between 1 (yes) and 0 (no).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d84e16846550d3b53937367204cdc32b2795485be09656f653af8979cce59232"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
