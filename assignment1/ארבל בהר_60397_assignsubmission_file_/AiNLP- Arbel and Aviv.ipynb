{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eaefe2-e138-4bd6-946e-3999cbebe1b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Exercise 1 - Ai & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e95ca3-c596-4bdf-ab71-61ca5508e9a5",
   "metadata": {},
   "source": [
    "Arbel Behar - 316534767,  Aviv Lohiet - 312467632"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106348d7-3f66-4d06-9678-6c6735403156",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b832b7-432c-4e82-82d6-ba0dc4fd3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arbel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c84cc-1423-42c5-a60d-2b4f675fa1b7",
   "metadata": {},
   "source": [
    "Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51cbb0c0-655a-409d-acd8-54c56fe677b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "data=pd.read_csv(r'C:\\Users\\arbel\\OneDrive - The Academic College of Tel-Aviv Jaffa - MTA\\spam_ham_dataset.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec74918-850d-4b90-a9f2-315dd5c54c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data to spam and ham\n",
    "spamData=data[data.loc[:,'label']=='spam']\n",
    "hamData=data[data.loc[:,'label']=='ham']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd66672-fb5e-4fb4-9ca7-4c9d524de309",
   "metadata": {},
   "source": [
    "Q2 - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a1b39b-6ac7-464d-b157-709d1962eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text column\n",
    "data['token_text']=data['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717fa8c8-2c52-44d6-84e6-b7e4d952314a",
   "metadata": {},
   "source": [
    "Q3 - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5d161b-d4f5-446e-82b2-9422100359d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8fb85\">\n",
       "  <caption>Frequency Table of the 10 most common Words in SPAM Data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8fb85_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_8fb85_level0_col1\" class=\"col_heading level0 col1\" >frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8fb85_row0_col0\" class=\"data row0 col0\" >subject</td>\n",
       "      <td id=\"T_8fb85_row0_col1\" class=\"data row0 col1\" >1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row1\" class=\"row_heading level0 row1\" >85</th>\n",
       "      <td id=\"T_8fb85_row1_col0\" class=\"data row1 col0\" >com</td>\n",
       "      <td id=\"T_8fb85_row1_col1\" class=\"data row1 col1\" >992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row2\" class=\"row_heading level0 row2\" >82</th>\n",
       "      <td id=\"T_8fb85_row2_col0\" class=\"data row2 col0\" >http</td>\n",
       "      <td id=\"T_8fb85_row2_col1\" class=\"data row2 col1\" >983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row3\" class=\"row_heading level0 row3\" >150</th>\n",
       "      <td id=\"T_8fb85_row3_col0\" class=\"data row3 col0\" >company</td>\n",
       "      <td id=\"T_8fb85_row3_col1\" class=\"data row3 col1\" >728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row4\" class=\"row_heading level0 row4\" >1289</th>\n",
       "      <td id=\"T_8fb85_row4_col0\" class=\"data row4 col0\" >www</td>\n",
       "      <td id=\"T_8fb85_row4_col1\" class=\"data row4 col1\" >587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row5\" class=\"row_heading level0 row5\" >1185</th>\n",
       "      <td id=\"T_8fb85_row5_col0\" class=\"data row5 col0\" >00</td>\n",
       "      <td id=\"T_8fb85_row5_col1\" class=\"data row5 col1\" >585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row6\" class=\"row_heading level0 row6\" >202</th>\n",
       "      <td id=\"T_8fb85_row6_col0\" class=\"data row6 col0\" >information</td>\n",
       "      <td id=\"T_8fb85_row6_col1\" class=\"data row6 col1\" >520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row7\" class=\"row_heading level0 row7\" >5847</th>\n",
       "      <td id=\"T_8fb85_row7_col0\" class=\"data row7 col0\" >font</td>\n",
       "      <td id=\"T_8fb85_row7_col1\" class=\"data row7 col1\" >515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row8\" class=\"row_heading level0 row8\" >5826</th>\n",
       "      <td id=\"T_8fb85_row8_col0\" class=\"data row8 col0\" >td</td>\n",
       "      <td id=\"T_8fb85_row8_col1\" class=\"data row8 col1\" >504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb85_level0_row9\" class=\"row_heading level0 row9\" >300</th>\n",
       "      <td id=\"T_8fb85_row9_col0\" class=\"data row9 col0\" >statements</td>\n",
       "      <td id=\"T_8fb85_row9_col1\" class=\"data row9 col1\" >476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a3467246a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spam\n",
    "vectorizer= CountVectorizer(lowercase=True,stop_words='english')\n",
    "spamWordBag=vectorizer.fit_transform(spamData['text'])\n",
    "# create dictionary for word frequncy\n",
    "wordSum=spamWordBag.sum(axis=0)\n",
    "wordFrequency=[(word,wordSum[0,idx])for word,idx in vectorizer.vocabulary_.items()]\n",
    "#create dataframe of ten high frequncy words\n",
    "spamDfFreq=pd.DataFrame(wordFrequency, columns=['word','frequency'])\n",
    "spamDfFreq=spamDfFreq.sort_values(by='frequency',ascending=False).head(10)\n",
    "\n",
    "spamDfFreq.style.set_caption('Frequency Table of the 10 most common Words in SPAM Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ae16fd-81ad-4183-9a6d-1963df92b5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c1e35\">\n",
       "  <caption>Frequency Table for 10 most common Words in HAM Data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c1e35_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_c1e35_level0_col1\" class=\"col_heading level0 col1\" >frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row0\" class=\"row_heading level0 row0\" >400</th>\n",
       "      <td id=\"T_c1e35_row0_col0\" class=\"data row0 col0\" >ect</td>\n",
       "      <td id=\"T_c1e35_row0_col1\" class=\"data row0 col1\" >13897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row1\" class=\"row_heading level0 row1\" >399</th>\n",
       "      <td id=\"T_c1e35_row1_col0\" class=\"data row1 col0\" >hou</td>\n",
       "      <td id=\"T_c1e35_row1_col1\" class=\"data row1 col1\" >7281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_c1e35_row2_col0\" class=\"data row2 col0\" >enron</td>\n",
       "      <td id=\"T_c1e35_row2_col1\" class=\"data row2 col1\" >6555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_c1e35_row3_col0\" class=\"data row3 col0\" >subject</td>\n",
       "      <td id=\"T_c1e35_row3_col1\" class=\"data row3 col1\" >6403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row4\" class=\"row_heading level0 row4\" >357</th>\n",
       "      <td id=\"T_c1e35_row4_col0\" class=\"data row4 col0\" >2000</td>\n",
       "      <td id=\"T_c1e35_row4_col1\" class=\"data row4 col1\" >4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row5\" class=\"row_heading level0 row5\" >24</th>\n",
       "      <td id=\"T_c1e35_row5_col0\" class=\"data row5 col0\" >gas</td>\n",
       "      <td id=\"T_c1e35_row5_col1\" class=\"data row5 col1\" >2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row6\" class=\"row_heading level0 row6\" >175</th>\n",
       "      <td id=\"T_c1e35_row6_col0\" class=\"data row6 col0\" >deal</td>\n",
       "      <td id=\"T_c1e35_row6_col1\" class=\"data row6 col1\" >2789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row7\" class=\"row_heading level0 row7\" >105</th>\n",
       "      <td id=\"T_c1e35_row7_col0\" class=\"data row7 col0\" >com</td>\n",
       "      <td id=\"T_c1e35_row7_col1\" class=\"data row7 col1\" >2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row8\" class=\"row_heading level0 row8\" >3</th>\n",
       "      <td id=\"T_c1e35_row8_col0\" class=\"data row8 col0\" >meter</td>\n",
       "      <td id=\"T_c1e35_row8_col1\" class=\"data row8 col1\" >2459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1e35_level0_row9\" class=\"row_heading level0 row9\" >347</th>\n",
       "      <td id=\"T_c1e35_row9_col0\" class=\"data row9 col0\" >cc</td>\n",
       "      <td id=\"T_c1e35_row9_col1\" class=\"data row9 col1\" >2359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a346724310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ham\n",
    "vectorizer= CountVectorizer(lowercase=True,stop_words='english')\n",
    "spamWordBag=vectorizer.fit_transform(hamData['text'])\n",
    "# create dictionary for word frequncy\n",
    "wordSum=spamWordBag.sum(axis=0)\n",
    "wordFrequency=[(word,wordSum[0,idx])for word,idx in vectorizer.vocabulary_.items()]\n",
    "#create dataframe of ten high frequncy words\n",
    "hamDfFreq=pd.DataFrame(wordFrequency,columns=['word','frequency'])\n",
    "hamDfFreq=hamDfFreq.sort_values(by='frequency',ascending=False).head(10)\n",
    "\n",
    "hamDfFreq.style.set_caption('Frequency Table for 10 most common Words in HAM Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bac994-dfb8-4061-9a0e-ac692df6db0f",
   "metadata": {},
   "source": [
    "Q4 - Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdc2b4f-ddbc-4041-b8ff-f61c9dc33089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the tfidf algorithm\n",
    "vectorizer=TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "tfidfData=vectorizer.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cb25b-42ff-493a-a64b-e1ecd8a8590b",
   "metadata": {},
   "source": [
    "Q5 - create Machine learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf459a2-419d-4427-a341-3f8070627ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define algorithm\n",
    "X=tfidfData\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= DecisionTreeClassifier()\n",
    "\n",
    "#model training\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#model testing\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95231063-2276-45d1-9587-8943713cacd5",
   "metadata": {},
   "source": [
    "Q6 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a92b58-e364-4ab1-9c49-d0147fcc3869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9432989690721649\n",
      "Precision: 0.8869936034115139\n",
      "Recall: 0.9223946784922394\n",
      "F1: 0.9043478260869565\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('Precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('Recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('F1:',metrics.f1_score(y_test,y_pred))\n",
    "#storage the metrics\n",
    "tfidfResultDT=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b3056-8c17-43c4-9dc7-2b3fb4f1ded1",
   "metadata": {},
   "source": [
    "Q7 - Different Algorithems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc97fa5-b353-44be-b065-34fc9824685b",
   "metadata": {},
   "source": [
    "1. Bag of words with Desicion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c7d47b-e4ad-4512-afa1-0979d6705f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9407216494845361\n",
      "Precision: 0.8876889848812095\n",
      "Recall: 0.9113082039911308\n",
      "F1: 0.899343544857768\n"
     ]
    }
   ],
   "source": [
    "#define the bag of words algorithm\n",
    "vectorizer=CountVectorizer(lowercase=True,stop_words='english')\n",
    "BoWData=vectorizer.fit_transform(data['text'])\n",
    "\n",
    "#define algorithm\n",
    "X=BoWData\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= DecisionTreeClassifier()\n",
    "\n",
    "#model training\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('Precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('Recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('F1:',metrics.f1_score(y_test,y_pred))\n",
    "#store metrics\n",
    "BoWResultDT=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                        metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08275e2d-7556-47c2-a34d-2bf8cc4485a7",
   "metadata": {},
   "source": [
    "2. Bag of Words with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053794c8-9f8c-4104-a11e-2912cf447805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9755154639175257\n",
      "Precision: 0.9384288747346072\n",
      "Recall: 0.9800443458980045\n",
      "F1: 0.9587852494577006\n"
     ]
    }
   ],
   "source": [
    "#define algorithm\n",
    "X=BoWData\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= svm.SVC()\n",
    "\n",
    "#model training\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('Precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('Recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('F1:',metrics.f1_score(y_test,y_pred))\n",
    "#store metrics\n",
    "BoWResultSvm=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08706f-ae93-483f-b801-ef8c761d134f",
   "metadata": {},
   "source": [
    "3. Tfidf with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2becaae7-6fe1-44c8-b3cd-500e4a2518bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9903350515463918\n",
      "Precision: 0.9718614718614719\n",
      "Recall: 0.9955654101995566\n",
      "F1: 0.9835706462212487\n"
     ]
    }
   ],
   "source": [
    "#define algorithm\n",
    "X=tfidfData\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= svm.SVC()\n",
    "\n",
    "#model training\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('Precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('Recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('F1:',metrics.f1_score(y_test,y_pred))\n",
    "#store metrics\n",
    "tfidfResultSvm=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                        metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572d244-179b-4d5e-a54e-0e3f5d3189f8",
   "metadata": {},
   "source": [
    "Q8 - Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9a74c5-3293-4e93-9a31-2ea721e6a3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tfidf dt</th>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.886994</td>\n",
       "      <td>0.922395</td>\n",
       "      <td>0.904348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoW dt</th>\n",
       "      <td>0.940722</td>\n",
       "      <td>0.887689</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.899344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoW svm</th>\n",
       "      <td>0.975515</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.980044</td>\n",
       "      <td>0.958785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf svm</th>\n",
       "      <td>0.990335</td>\n",
       "      <td>0.971861</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>0.983571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision    Recall  F1 Score\n",
       "Tfidf dt   0.943299   0.886994  0.922395  0.904348\n",
       "BoW dt     0.940722   0.887689  0.911308  0.899344\n",
       "BoW svm    0.975515   0.938429  0.980044  0.958785\n",
       "Tfidf svm  0.990335   0.971861  0.995565  0.983571"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparison of the results\n",
    "metrics_data=pd.DataFrame(data=[tfidfResultDT,BoWResultDT,BoWResultSvm,tfidfResultSvm]\n",
    "                         ,columns=['Accuracy','Precision','Recall','F1 Score'])\n",
    "metrics_data.rename(index={0:'Tfidf dt',1:'BoW dt',2:'BoW svm',3:'Tfidf svm'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b16b2-6e87-4d4d-8de6-209dd1d594e7",
   "metadata": {},
   "source": [
    "Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa532d-aad2-451a-af0c-a636056da66e",
   "metadata": {},
   "source": [
    "Once we split the word data using tfidf we can get a more accurate represantation of the words and their variations.\n",
    "Using the SVM on the tfidf we can see that we get the most accurate result.\n",
    "The reason is that SVM can divide the data in a more accurate way when there aren't a clear categories for the words unlike the DT that suits categorized data more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
