{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80d2449",
   "metadata": {},
   "source": [
    "# Excersice 1 \n",
    "    name: <Tal Bardugo - 207276635 , Eden Aladjem - 315240481>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff046c8",
   "metadata": {},
   "source": [
    "## import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fc0670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asaf1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#import data\n",
    "data=pd.read_csv(r'C:\\Users\\asaf1\\OneDrive - The Academic College of Tel-Aviv Jaffa - MTA\\שנה ג\\AI\\spam_ham_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "292d3fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ca820",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d25dc81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data=data[data.loc[:,'label']=='spam']\n",
    "ham_data=data[data.loc[:,'label']=='ham']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11203023",
   "metadata": {},
   "source": [
    "### Q2. toeknization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cf5f90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization of text column\n",
    "data['tokens']=data['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b7cef",
   "metadata": {},
   "source": [
    "### Q3. EDA for token frequncy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e1d65f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam\n",
    "vectorizer= CountVectorizer(lowercase=True,stop_words='english')\n",
    "spam_bag=vectorizer.fit_transform(spam_data['text'])\n",
    "# create dictionary which contain the word frequncy \n",
    "sum_words=spam_bag.sum(axis=0)\n",
    "word_freq=[(word,sum_words[0,idx])for word,idx in vectorizer.vocabulary_.items()]\n",
    "#create dataframe of the tenth highly frequncy words\n",
    "freq_df_spam=pd.DataFrame(word_freq, columns=['word','frequency'])\n",
    "freq_df_spam=freq_df_spam.sort_values(by='frequency',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f5cb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham\n",
    "vectorizer= CountVectorizer(lowercase=True,stop_words='english')\n",
    "spam_bag=vectorizer.fit_transform(ham_data['text'])\n",
    "# create dictionary which contain the word frequncy \n",
    "sum_words=spam_bag.sum(axis=0)\n",
    "word_freq=[(word,sum_words[0,idx])for word,idx in vectorizer.vocabulary_.items()]\n",
    "#create dataframe of the tenth highly frequncy words\n",
    "freq_df_ham=pd.DataFrame(word_freq,columns=['word','frequency'])\n",
    "freq_df_ham=freq_df_ham.sort_values(by='frequency',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b93df088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_561af\">\n",
       "  <caption>Frequency Table of the 10 most common Words in HAM Data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_561af_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_561af_level0_col1\" class=\"col_heading level0 col1\" >frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row0\" class=\"row_heading level0 row0\" >400</th>\n",
       "      <td id=\"T_561af_row0_col0\" class=\"data row0 col0\" >ect</td>\n",
       "      <td id=\"T_561af_row0_col1\" class=\"data row0 col1\" >13897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row1\" class=\"row_heading level0 row1\" >399</th>\n",
       "      <td id=\"T_561af_row1_col0\" class=\"data row1 col0\" >hou</td>\n",
       "      <td id=\"T_561af_row1_col1\" class=\"data row1 col1\" >7281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_561af_row2_col0\" class=\"data row2 col0\" >enron</td>\n",
       "      <td id=\"T_561af_row2_col1\" class=\"data row2 col1\" >6555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_561af_row3_col0\" class=\"data row3 col0\" >subject</td>\n",
       "      <td id=\"T_561af_row3_col1\" class=\"data row3 col1\" >6403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row4\" class=\"row_heading level0 row4\" >357</th>\n",
       "      <td id=\"T_561af_row4_col0\" class=\"data row4 col0\" >2000</td>\n",
       "      <td id=\"T_561af_row4_col1\" class=\"data row4 col1\" >4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row5\" class=\"row_heading level0 row5\" >24</th>\n",
       "      <td id=\"T_561af_row5_col0\" class=\"data row5 col0\" >gas</td>\n",
       "      <td id=\"T_561af_row5_col1\" class=\"data row5 col1\" >2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row6\" class=\"row_heading level0 row6\" >175</th>\n",
       "      <td id=\"T_561af_row6_col0\" class=\"data row6 col0\" >deal</td>\n",
       "      <td id=\"T_561af_row6_col1\" class=\"data row6 col1\" >2789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row7\" class=\"row_heading level0 row7\" >105</th>\n",
       "      <td id=\"T_561af_row7_col0\" class=\"data row7 col0\" >com</td>\n",
       "      <td id=\"T_561af_row7_col1\" class=\"data row7 col1\" >2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row8\" class=\"row_heading level0 row8\" >3</th>\n",
       "      <td id=\"T_561af_row8_col0\" class=\"data row8 col0\" >meter</td>\n",
       "      <td id=\"T_561af_row8_col1\" class=\"data row8 col1\" >2459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_561af_level0_row9\" class=\"row_heading level0 row9\" >347</th>\n",
       "      <td id=\"T_561af_row9_col0\" class=\"data row9 col0\" >cc</td>\n",
       "      <td id=\"T_561af_row9_col1\" class=\"data row9 col1\" >2359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x203819a00a0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df_ham.style.set_caption('Frequency Table of the 10 most common Words in HAM Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "abd5546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_328c2\">\n",
       "  <caption>Frequency Table of the 10 most common Words in SPAM Data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_328c2_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_328c2_level0_col1\" class=\"col_heading level0 col1\" >frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_328c2_row0_col0\" class=\"data row0 col0\" >subject</td>\n",
       "      <td id=\"T_328c2_row0_col1\" class=\"data row0 col1\" >1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row1\" class=\"row_heading level0 row1\" >85</th>\n",
       "      <td id=\"T_328c2_row1_col0\" class=\"data row1 col0\" >com</td>\n",
       "      <td id=\"T_328c2_row1_col1\" class=\"data row1 col1\" >992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row2\" class=\"row_heading level0 row2\" >82</th>\n",
       "      <td id=\"T_328c2_row2_col0\" class=\"data row2 col0\" >http</td>\n",
       "      <td id=\"T_328c2_row2_col1\" class=\"data row2 col1\" >983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row3\" class=\"row_heading level0 row3\" >150</th>\n",
       "      <td id=\"T_328c2_row3_col0\" class=\"data row3 col0\" >company</td>\n",
       "      <td id=\"T_328c2_row3_col1\" class=\"data row3 col1\" >728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row4\" class=\"row_heading level0 row4\" >1289</th>\n",
       "      <td id=\"T_328c2_row4_col0\" class=\"data row4 col0\" >www</td>\n",
       "      <td id=\"T_328c2_row4_col1\" class=\"data row4 col1\" >587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row5\" class=\"row_heading level0 row5\" >1185</th>\n",
       "      <td id=\"T_328c2_row5_col0\" class=\"data row5 col0\" >00</td>\n",
       "      <td id=\"T_328c2_row5_col1\" class=\"data row5 col1\" >585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row6\" class=\"row_heading level0 row6\" >202</th>\n",
       "      <td id=\"T_328c2_row6_col0\" class=\"data row6 col0\" >information</td>\n",
       "      <td id=\"T_328c2_row6_col1\" class=\"data row6 col1\" >520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row7\" class=\"row_heading level0 row7\" >5847</th>\n",
       "      <td id=\"T_328c2_row7_col0\" class=\"data row7 col0\" >font</td>\n",
       "      <td id=\"T_328c2_row7_col1\" class=\"data row7 col1\" >515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row8\" class=\"row_heading level0 row8\" >5826</th>\n",
       "      <td id=\"T_328c2_row8_col0\" class=\"data row8 col0\" >td</td>\n",
       "      <td id=\"T_328c2_row8_col1\" class=\"data row8 col1\" >504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_328c2_level0_row9\" class=\"row_heading level0 row9\" >300</th>\n",
       "      <td id=\"T_328c2_row9_col0\" class=\"data row9 col0\" >statements</td>\n",
       "      <td id=\"T_328c2_row9_col1\" class=\"data row9 col1\" >476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x203816a8dc0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df_spam.style.set_caption('Frequency Table of the 10 most common Words in SPAM Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a781d",
   "metadata": {},
   "source": [
    "### Q.4 Tf-IDF method for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1de611ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the tfidf algorithm\n",
    "vectorizer=TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "tf_idf_data=vectorizer.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f67a3b",
   "metadata": {},
   "source": [
    "### Q.5 +Q6 create Machine learning model to predict spam\\ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "824cc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3843ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9452319587628866\n",
      "precision: 0.8828451882845189\n",
      "recall: 0.9356984478935698\n",
      "f1: 0.9085037674919267\n"
     ]
    }
   ],
   "source": [
    "#define algorithm\n",
    "X=tf_idf_data\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= DecisionTreeClassifier()\n",
    "\n",
    "#traint the model\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('f1:',metrics.f1_score(y_test,y_pred))\n",
    "#storage the metrics\n",
    "result_tfidf_td=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32035638",
   "metadata": {},
   "source": [
    "### Q7\n",
    "in the next section i'll run: <br>\n",
    "1. bag of words with Decision tree\n",
    "2. tfidf with SVM(support vector machines\n",
    "3. bag of words with SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d586c",
   "metadata": {},
   "source": [
    "#### Q7.1 bag of words with Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e799e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the bag of words algorithm\n",
    "vectorizer=CountVectorizer(lowercase=True,stop_words='english')\n",
    "bow_data=vectorizer.fit_transform(data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b987ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9420103092783505\n",
      "precision: 0.8915401301518439\n",
      "recall: 0.9113082039911308\n",
      "f1: 0.9013157894736842\n"
     ]
    }
   ],
   "source": [
    "#define algorithm\n",
    "X=bow_data\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= DecisionTreeClassifier()\n",
    "\n",
    "#traint the model\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('f1:',metrics.f1_score(y_test,y_pred))\n",
    "#storage the metrics\n",
    "result_bow_td=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad4722",
   "metadata": {},
   "source": [
    "### Q7.2 tfidf with SVM(support vector machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3698bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3dd73215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9903350515463918\n",
      "precision: 0.9718614718614719\n",
      "recall: 0.9955654101995566\n",
      "f1: 0.9835706462212487\n"
     ]
    }
   ],
   "source": [
    "#define algorithm\n",
    "X=tf_idf_data\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= svm.SVC()\n",
    "\n",
    "#traint the model\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('f1:',metrics.f1_score(y_test,y_pred))\n",
    "#storage the metrics\n",
    "result_tfidf_svm=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec5b52",
   "metadata": {},
   "source": [
    "### Q7.3  bag of words with SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ab82f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9755154639175257\n",
      "precision: 0.9384288747346072\n",
      "recall: 0.9800443458980045\n",
      "f1: 0.9587852494577006\n"
     ]
    }
   ],
   "source": [
    "#define algorithm\n",
    "X=bow_data\n",
    "y=data['label_num']\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "clf= svm.SVC()\n",
    "\n",
    "#traint the model\n",
    "clf=clf.fit(X_train,y_train)\n",
    "#test the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#evaluation\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('precision:',metrics.precision_score(y_test,y_pred))\n",
    "print('recall:',metrics.recall_score(y_test,y_pred))\n",
    "print('f1:',metrics.f1_score(y_test,y_pred))\n",
    "#storage the metrics\n",
    "result_bow_svm=[metrics.accuracy_score(y_test,y_pred),metrics.precision_score(y_test,y_pred),\n",
    "                metrics.recall_score(y_test,y_pred),metrics.f1_score(y_test,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973601f5",
   "metadata": {},
   "source": [
    "### Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "505cc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat emetrics table of the 4 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "efcbeeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf_td</th>\n",
       "      <td>0.945232</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.935698</td>\n",
       "      <td>0.908504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow_td</th>\n",
       "      <td>0.942010</td>\n",
       "      <td>0.891540</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.901316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow_svm</th>\n",
       "      <td>0.975515</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.980044</td>\n",
       "      <td>0.958785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_svm</th>\n",
       "      <td>0.990335</td>\n",
       "      <td>0.971861</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>0.983571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision    Recall  F1 Score\n",
       "tfidf_td   0.945232   0.882845  0.935698  0.908504\n",
       "bow_td     0.942010   0.891540  0.911308  0.901316\n",
       "bow_svm    0.975515   0.938429  0.980044  0.958785\n",
       "tfidf_svm  0.990335   0.971861  0.995565  0.983571"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data=pd.DataFrame(data=[result_tfidf_td,result_bow_td,result_bow_svm,result_tfidf_svm]\n",
    "                         ,columns=['Accuracy','Precision','Recall','F1 Score'])\n",
    "metrics_data.rename(index={0:'tfidf_td',1:'bow_td',2:'bow_svm',3:'tfidf_svm'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389c156",
   "metadata": {},
   "source": [
    "### Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "909bfa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The TFIDF algorithm more correctly represents the corpus\n",
    "#it also represents the total frequency of the word in the text in combination with its frequency in all documents,\n",
    "#unlike BOW which only represents the frequency of the word in the text.\n",
    "#The theoretical analysis concludes that SVMs acknowledge\n",
    "#the particular properties of text: 1. high dimensional feature spaces, 2. few irrelevant features , and 3. sparse instance vectors.\n",
    "#These advantages give an advantage to text analysis and prediction, in addition there are articles that present empirical experiments that SVM is an algorithm that gives high performance to NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
