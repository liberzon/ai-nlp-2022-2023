{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ohad Ezer 207439043\n",
    "#Ofri siso 206698870"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing all Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import metrics as metrics\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import snowball\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import collections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from nltk.translate import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer as porter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read CSV file and load to Dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removing text label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df = df[['text', 'label_num']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False, preprocessor=lambda x: x, tokenizer=lambda x: x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create function for count metrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_matrix(text_df_input, model_input):\n",
    "    matrix = model.fit_transform(text_df_input).toarray()\n",
    "    return pd.DataFrame(data=matrix, columns=model_input.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# split into spam DF and han DF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "df_temp = df.copy()\n",
    "df_temp['tokens'] = [','.join(map(str, l)) for l in df_temp['tokens']]\n",
    "df_ham = df[df_temp['label_num'] == 0]\n",
    "df_spam = df[df_temp['label_num'] == 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Print ham tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam tokens\n",
      "      \u0001  \u0007  \u000F  \u0012  !  #  $  %  &   '  ...  zone  zones  zufferli  zukin  \\\n",
      "0     0  0  0  0  0  1  0  0  0   1  ...     0      0         0      0   \n",
      "1     0  0  0  0  0  0  0  0  0   0  ...     0      0         0      0   \n",
      "2     0  0  0  0  4  0  0  0  0  16  ...     0      0         0      0   \n",
      "3     0  0  0  0  0  0  0  0  0   1  ...     0      0         0      0   \n",
      "4     0  0  0  0  0  0  0  0  0   0  ...     0      0         0      0   \n",
      "...  .. .. .. .. .. .. .. .. ..  ..  ...   ...    ...       ...    ...   \n",
      "3667  0  0  0  0  0  4  2  0  0   0  ...     0      0         0      0   \n",
      "3668  0  0  0  0  0  0  0  0  0   0  ...     0      0         0      0   \n",
      "3669  0  0  0  0  0  0  0  0  2   2  ...     0      0         0      0   \n",
      "3670  0  0  0  0  0  0  0  0  0   0  ...     0      0         0      0   \n",
      "3671  0  0  0  0  0  0  0  0  1   1  ...     0      0         0      0   \n",
      "\n",
      "      zwiers  zzn  {  |  }  ~  \n",
      "0          0    0  2  0  2  0  \n",
      "1          0    0  0  0  0  0  \n",
      "2          0    0  0  0  0  0  \n",
      "3          0    0  0  0  0  0  \n",
      "4          0    0  0  0  0  0  \n",
      "...      ...  ... .. .. .. ..  \n",
      "3667       0    0  0  0  0  0  \n",
      "3668       0    0  0  0  0  0  \n",
      "3669       0    0  0  0  0  0  \n",
      "3670       0    0  0  0  0  0  \n",
      "3671       0    0  1  0  1  0  \n",
      "\n",
      "[3672 rows x 20249 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OfriSiso\\anaconda3\\envs\\pythonProject1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"not spam tokens\")\n",
    "text_df = df_ham['tokens']\n",
    "model = CountVectorizer(lowercase=False, preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "m1 = get_matrix(text_df, model)\n",
    "print(m1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Print spam tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam tokens\n",
      "      \u0005  \u0011  \u0012  \u0013  \u0014  \u0016  \u001B  !  #  $  ...  zyyqywp  zzezrjok  zzo  zzocb  zzso  \\\n",
      "0     0  0  0  0  0  0  0  0  0  0  ...        0         0    0      0     0   \n",
      "1     0  0  0  0  0  0  0  3  0  0  ...        0         0    0      0     0   \n",
      "2     0  0  0  0  0  0  0  0  0  7  ...        0         0    0      0     0   \n",
      "3     0  0  0  0  0  0  0  3  0  0  ...        0         0    0      0     0   \n",
      "4     0  0  0  0  0  0  0  0  0  0  ...        0         0    0      0     0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...      ...       ...  ...    ...   ...   \n",
      "1494  0  0  0  0  0  0  0  0  0  0  ...        0         0    0      0     0   \n",
      "1495  0  0  0  0  0  0  0  3  0  0  ...        0         0    0      0     0   \n",
      "1496  0  0  0  0  0  0  0  0  0  0  ...        0         0    0      0     0   \n",
      "1497  0  0  0  0  0  0  0  1  0  0  ...        0         0    0      0     0   \n",
      "1498  0  0  0  0  0  0  0  0  0  0  ...        0         0    0      0     0   \n",
      "\n",
      "      zzsyt  {   |  }  ~  \n",
      "0         0  0   0  0  0  \n",
      "1         0  0   0  0  0  \n",
      "2         0  0   0  0  0  \n",
      "3         0  0   0  0  0  \n",
      "4         0  0   0  0  0  \n",
      "...     ... ..  .. .. ..  \n",
      "1494      0  0   0  0  0  \n",
      "1495      0  0  20  0  0  \n",
      "1496      0  0   0  0  0  \n",
      "1497      0  0   0  0  0  \n",
      "1498      0  0   0  0  0  \n",
      "\n",
      "[1499 rows x 38750 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OfriSiso\\anaconda3\\envs\\pythonProject1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"spam tokens\")\n",
    "text_df = df_spam['tokens']\n",
    "model = CountVectorizer(lowercase=False, preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "m2 = get_matrix(text_df, model)\n",
    "print(m2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get and print features names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OfriSiso\\anaconda3\\envs\\pythonProject1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<5171x50524 sparse matrix of type '<class 'numpy.int64'>'\n\twith 518169 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = df['tokens'].tolist()\n",
    "vectorizer.fit(docs)\n",
    "vectorizer.get_feature_names_out()\n",
    "vectorizer.transform(docs)\n",
    "vectorizer.fit_transform(docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def get_matrix(text_df_input, model_input):\n",
    "    matrix = model.fit_transform(text_df_input).toarray()\n",
    "    return pd.DataFrame(data=matrix, columns=model_input.get_feature_names())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split into test and train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('label_num', axis=1)\n",
    "y = df['label_num']\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=1234)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for list in df['tokens']:\n",
    "    vocabulary += list\n",
    "wordset = set(vocabulary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x01' '\\x05' '\\x07' ... '|' '}' '~']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(vocabulary=wordset, lowercase=False)\n",
    "print(count_vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "X_train = count_vectorizer.fit_transform(train['text'])\n",
    "X_test = count_vectorizer.fit_transform(test['text'])\n",
    "y_train = train['label_num']\n",
    "y_test = test['label_num']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Models:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model num 1 - Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768115942028985\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(C=5, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "score1 = classifier.score(X_test, y_test)\n",
    "print(score1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model num 2 - KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "k= int(math.sqrt(X_train.shape[0])/2)\n",
    "if k%2 ==0:\n",
    "    k+=1\n",
    "\n",
    "clf= KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_test =clf.predict(X_test)\n",
    "score2= accuracy_score(y_test, y_pred_test)\n",
    "print(score2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model num 3 - decision tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9439613526570049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1234)\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score3 = accuracy_score(y_test,y_pred)\n",
    "print(score3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model num 4 - svm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603864734299516\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_test=model.predict(X_test)\n",
    "score4= metrics.accuracy_score(y_test,y_pred_test)\n",
    "print(score4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create scores table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name             Accuracy score\n",
      "-------------------  ----------------\n",
      "Logistic Regression          0.976812\n",
      "KNN                          0.822222\n",
      "Decision Tree                0.943961\n",
      "SVM                          0.960386\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "table = [[\"model_name\", \"Accuracy score\"],\n",
    "        [\"Logistic Regression\",score1],\n",
    "        [\"KNN\",score2],\n",
    "        [\"Decision Tree\",score3],\n",
    "        [\"SVM\",score4]]\n",
    "\n",
    "print(tabulate(table, headers='firstrow'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The most accurate model was linear regression. The model is particularly suitable for simple classification problems and therefore worked well in this case"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
