{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 22.9.0\r\n",
      "  latest version: 22.11.1\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "Retrieving notices: ...working... done\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -y spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 22.9.0\r\n",
      "  latest version: 22.11.1\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "Retrieving notices: ...working... done\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -y spacy-lookups-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemmatizer          \n",
      "friend              friend              \n",
      "friendship          friendship          \n",
      "friends             friend              \n",
      "friendships         friendship          \n",
      "stabil              stabil              \n",
      "destabilize         destabilize         \n",
      "misunderstanding    misunderstanding    \n",
      "railroad            railroad            \n",
      "moonlight           moonlight           \n",
      "football            football            \n"
     ]
    }
   ],
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}\".format(\"Word\", \"Lemmatizer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatizer.lemmatize(word)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks: rock\n",
      "corpora: corpus\n",
      "indices: index\n",
      "better: good\n",
      "better: better\n"
     ]
    }
   ],
   "source": [
    "print(\"rocks:\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora:\", lemmatizer.lemmatize(\"corpora\"))\n",
    "print(\"indices:\", lemmatizer.lemmatize(\"indices\"))\n",
    "print(\"better:\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
    "print(\"better:\", lemmatizer.lemmatize(\"better\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scikit-Learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "bow_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "sample_text = \"Apple is looking at buying U.K. startup for $1 billion\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp(sample_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2a276c220>),\n ('tagger', <spacy.pipeline.tagger.Tagger at 0x2a276c760>),\n ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x162954200>),\n ('attribute_ruler',\n  <spacy.pipeline.attributeruler.AttributeRuler at 0x2a00cf500>),\n ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2933c2b00>),\n ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2c3172970>)]"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "['Apple',\n 'is',\n 'looking',\n 'at',\n 'buying',\n 'U.K.',\n 'startup',\n 'for',\n '$',\n '1',\n 'billion']"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = []\n",
    "for token in tokens:\n",
    "    token_list.append(token.text)\n",
    "token_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "['Apple',\n 'be',\n 'look',\n 'at',\n 'buy',\n 'U.K.',\n 'startup',\n 'for',\n '$',\n '1',\n 'billion']"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_list = []\n",
    "for token in tokens:\n",
    "    lemma_list.append(token.lemma_)\n",
    "lemma_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
