{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 22.9.0\r\n",
      "  latest version: 22.11.1\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "Retrieving notices: ...working... done\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -y spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 22.9.0\r\n",
      "  latest version: 22.11.1\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "Retrieving notices: ...working... done\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -y spacy-lookups-data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemmatizer          \n",
      "friend              friend              \n",
      "friendship          friendship          \n",
      "friends             friend              \n",
      "friendships         friendship          \n",
      "stabil              stabil              \n",
      "destabilize         destabilize         \n",
      "misunderstanding    misunderstanding    \n",
      "railroad            railroad            \n",
      "moonlight           moonlight           \n",
      "football            football            \n"
     ]
    }
   ],
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}\".format(\"Word\", \"Lemmatizer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatizer.lemmatize(word)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks: rock\n",
      "corpora: corpus\n",
      "indices: index\n",
      "better: good\n",
      "better: better\n"
     ]
    }
   ],
   "source": [
    "print(\"rocks:\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora:\", lemmatizer.lemmatize(\"corpora\"))\n",
    "print(\"indices:\", lemmatizer.lemmatize(\"indices\"))\n",
    "print(\"better:\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
    "print(\"better:\", lemmatizer.lemmatize(\"better\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scikit-Learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "bow_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "sample_text = \"Apple is looking at buying U.K. startup for $1 billion\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp(sample_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "['Apple',\n 'is',\n 'looking',\n 'at',\n 'buying',\n 'U.K.',\n 'startup',\n 'for',\n '$',\n '1',\n 'billion']"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = []\n",
    "for token in tokens:\n",
    "    token_list.append(token.text)\n",
    "token_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "['Apple',\n 'be',\n 'look',\n 'at',\n 'buy',\n 'U.K.',\n 'startup',\n 'for',\n '$',\n '1',\n 'billion']"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_list = []\n",
    "for token in tokens:\n",
    "    lemma_list.append(token.lemma_)\n",
    "lemma_list"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
